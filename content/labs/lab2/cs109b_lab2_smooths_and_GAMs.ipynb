{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109B Data Science 2: Advanced Topics in Data Science \n",
    "## Lab 2 - Smoothers and Generalized Additive Models\n",
    "\n",
    "\n",
    "**Harvard University**<br>\n",
    "**Spring 2019**<br>\n",
    "**Instructors:** Mark Glickman and Pavlos Protopapas<br>\n",
    "**Lab Instructors:** Will Claybaugh<br>\n",
    "**Contributors:** Paul Tyklin and Will Claybaugh\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "div.discussion {\n",
       "\tbackground-color: #ccffcc;\n",
       "\tborder-color: #88E97A;\n",
       "\tborder-left: 5px solid #0A8000; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES\n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "\n",
    "The main goal of this lab is to get familiar with calling R functions within Python. Along the way, we'll learn about the \"formula\" interface to statsmodels, which gives an intuitive way of specifying regression models, and we'll review the different approaches to fitting curves.\n",
    "\n",
    "Key Skills:\n",
    "- Importing (base) R functions\n",
    "- Importing R library functions\n",
    "- Populating vectors R understands\n",
    "- Populating dataframes R understands\n",
    "- Populating formulas R understands\n",
    "- Running models in R\n",
    "- Getting results back to Python\n",
    "- Getting model predictions in R\n",
    "- Plotting in R\n",
    "- Reading R's documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear/Polynomial Regression (Python, Review)\n",
    "Hopefully, you remember working with Statsmodels during 109a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data and (some) exploring in Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diab = pd.read_csv(\"data/diabetes.csv\")\n",
    "print(\"\"\"\n",
    "# Variables are:\n",
    "#   subject:   subject ID number\n",
    "#   age:       age diagnosed with diabetes\n",
    "#   acidity:   a measure of acidity called base deficit\n",
    "#   y:         natural log of serum C-peptide concentration\n",
    "#\n",
    "# Original source is Sockett et al. (1987)\n",
    "# mentioned in Hastie and Tibshirani's book \n",
    "# \"Generalized Additive Models\".\n",
    "\"\"\")\n",
    "\n",
    "display(diab.head())\n",
    "display(diab.dtypes)\n",
    "display(diab.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting with matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax0 = diab.plot.scatter(x='age',y='y',c='Red',title=\"Diabetes data\") #plotting direclty from pandas!\n",
    "ax0.set_xlabel(\"Age at Diagnosis\")\n",
    "ax0.set_ylabel(\"Log C-Peptide Concentration\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression with statsmodels. \n",
    "\n",
    "- Previously, we worked from a vector of target values and a design matrix we built ourself (e.g. from PolynomialFeatures). \n",
    "- Now, Statsmodels' *formula interface* can help build the target value and design matrix for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using statsmodels\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "\n",
    "model1 = sm.ols('y ~ age',data=diab)\n",
    "fit1_lm = model1.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a data frame to predict values on (sometimes this is just the test or validation set)\n",
    " - Very useful for making pretty plots of the model predcitions -- predict for TONS of values, not just whatever's in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = np.linspace(0,16,100)\n",
    "\n",
    "predict_df = pd.DataFrame(data={\"age\":x_pred})\n",
    "predict_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `get_prediction(<data>).summary_frame()` to get the model's prediction (and error bars!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_output = fit1_lm.get_prediction(predict_df).summary_frame()\n",
    "prediction_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the model and error bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = diab.plot.scatter(x='age',y='y',c='Red',title=\"Diabetes data with least-squares linear fit\")\n",
    "ax1.set_xlabel(\"Age at Diagnosis\")\n",
    "ax1.set_ylabel(\"Log C-Peptide Concentration\")\n",
    "\n",
    "\n",
    "ax1.plot(predict_df.age, prediction_output['mean'],color=\"green\")\n",
    "ax1.plot(predict_df.age, prediction_output['mean_ci_lower'], color=\"blue\",linestyle=\"dashed\")\n",
    "ax1.plot(predict_df.age, prediction_output['mean_ci_upper'], color=\"blue\",linestyle=\"dashed\");\n",
    "\n",
    "ax1.plot(predict_df.age, prediction_output['obs_ci_lower'], color=\"skyblue\",linestyle=\"dashed\")\n",
    "ax1.plot(predict_df.age, prediction_output['obs_ci_upper'], color=\"skyblue\",linestyle=\"dashed\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"discussion\"><b>Discussion</b></div>\n",
    "\n",
    "- What are the dark error bars? \n",
    "- What are the light error bars?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 1</b></div>\n",
    "\n",
    "1. Fit a 3rd degree polynomial model and plot the model+error bars\n",
    " - Route1: Build a design df with a column for each of `age`, `age**2`, `age**3`\n",
    " - Route2: Just edit the formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers**:\n",
    "\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear/Polynomial Regression, but make it R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the meat of the lab. After this section we'll know everything we need to in order to work with R models. The rest of the lab is just applying these concepts to run particular models. This section therefore is your 'cheat sheet' for working in R.\n",
    "\n",
    "What we need to know:\n",
    "- Importing (base) R functions\n",
    "- Importing R Library functions\n",
    "- Populating vectors R understands\n",
    "- Populating DataFrames R understands\n",
    "- Populating Formulas R understands\n",
    "- Running models in R\n",
    "- Getting results back to Python\n",
    "- Getting model predictions in R\n",
    "- Plotting in R\n",
    "- Reading R's documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing R functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you're on JupyterHub you may need to specify the path to R\n",
    "\n",
    "#import os\n",
    "#os.environ['R_HOME'] = \"/usr/share/anaconda3/lib/R\"\n",
    "\n",
    "import rpy2.robjects as robjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_lm = robjects.r[\"lm\"]\n",
    "r_predict = robjects.r[\"predict\"]\n",
    "#r_plot = robjects.r[\"plot\"] # more on plotting later\n",
    "\n",
    "#lm() and predict() are two of the most common functions we'll use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing R libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "#r_cluster = importr('cluster')\n",
    "#r_cluster.pam;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Populating vectors R understands**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_y = robjects.FloatVector(diab['y'])\n",
    "r_age = robjects.FloatVector(diab['age'])\n",
    "# What happens if we pass the wrong type?\n",
    "# How does r_age display?\n",
    "# How does r_age print?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Populating Data Frames R understands**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diab_r = robjects.DataFrame({\"y\":r_y, \"age\":r_age})\n",
    "# How does diab_r display?\n",
    "# How does diab_r print?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Populating formulas R understands**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_formula = robjects.Formula(\"y~age\")\n",
    "simple_formula.environment[\"y\"] = r_y #populate the formula's .environment, so it knows what 'y' and 'age' refer to\n",
    "simple_formula.environment[\"age\"] = r_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running Models in R**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diab_lm = r_lm(formula=simple_formula) # the formula object is storing all the needed variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_formula = robjects.Formula(\"y~age\") # reset the formula\n",
    "diab_lm = r_lm(formula=simple_formula, data=diab_r) #can also use a 'dumb' formula and pass a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting results back to Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diab_lm #the result is already 'in' python, but it's a special object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diab_lm.names) # view all names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diab_lm[0] #grab the first element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diab_lm.rx2(\"coefficients\") #use rx2 to get elements by name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(diab_lm.rx2(\"coefficients\")) #r vectors can be converted to numpy (but rarely needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a df to predict on (might just be the validation or test dataframe)\n",
    "predict_df = robjects.DataFrame({\"age\": robjects.FloatVector(np.linspace(0,16,100))})\n",
    "\n",
    "# call R's predict() function, passing the model and the data \n",
    "predictions = r_predict(diab_lm, predict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = predict_df.rx2(\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = diab.plot.scatter(x='age',y='y',c='Red',title=\"Diabetes data\")\n",
    "ax.set_xlabel(\"Age at Diagnosis\")\n",
    "ax.set_ylabel(\"Log C-Peptide Concentration\");\n",
    "\n",
    "ax.plot(x_vals,predictions); #plt still works with r vectors as input!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting in R**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The above turns on the %R \"magic\"\n",
    "- R's plot() command responds differently based on what you hand to it; Different models get different plots!\n",
    " - For any specific model search for plot.modelname. E.g. for a GAM model, search plot.gam for any details of plotting a GAM model\n",
    "- The %R \"magic\" runs R code in 'notebook' mode, so figures display nicely\n",
    "  - Ahead of the `plot(<model>)` code we pass in the variables R needs to know about (`-i` is for \"input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%R -i diab_lm plot(diab_lm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading R's documentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation for the `lm()` funciton is [here](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/lm.html), and a prettier version (same content) is [here](https://www.rdocumentation.org/packages/stats/versions/3.5.2/topics/lm). When googling, perfer rdocumentation.org when possible.\n",
    "Sections:\n",
    " - **Usage**: gives the function signature, including all optional arguments\n",
    " - **Arguments**: What each function input controls\n",
    " - **Details**: additional info on what the funciton *does* and how arguments interact. **Often the right place to start reading**\n",
    " - **Value**: the structure of the object returned by the function\n",
    " - **Refferences**: The relevant academic papers\n",
    " - **See Also**: other functions of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 2</b></div>\n",
    "\n",
    "1. Add confidence intervals calculated in R to the linear regression plot above. Use the `interval=` argument to `r_predict()` (documentation [here](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/predict.lm.html)). You will have to work with a matrix returned by R.\n",
    "2. Fit a 5th degree polynomial to the diabetes data in R. Search the web for an easier method than writing out a formula with all 5 polynomial terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers**\n",
    "\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowess Smoothing\n",
    "Lowess Smoothing is implemented in both Python and R. We'll use it as another example as we transition languages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"discussion\"><b>Discussion</b></div>\n",
    "\n",
    " - What is lowess smoothing? Which 109a models is it related to?\n",
    " - How explainable is lowess?\n",
    " - What are the tunable parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.nonparametric.smoothers_lowess import lowess as lowess\n",
    "\n",
    "ss1 = lowess(diab['y'],diab['age'],frac=0.15)\n",
    "ss2 = lowess(diab['y'],diab['age'],frac=0.25)\n",
    "ss3 = lowess(diab['y'],diab['age'],frac=0.7)\n",
    "ss4 = lowess(diab['y'],diab['age'],frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss1[:10,:] # we get back simple a smoothed y value for each x value in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the clean code to plot different models. We'll see even cleaner code in a minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cur_model, cur_frac in zip([ss1,ss2,ss3,ss4],[0.15,0.25,0.7,1]):\n",
    "\n",
    "    ax = diab.plot.scatter(x='age',y='y',c='Red',title=\"Lowess Fit, Fraction = {}\".format(cur_frac))\n",
    "    ax.set_xlabel(\"Age at Diagnosis\")\n",
    "    ax.set_ylabel(\"Log C-Peptide Concentration\")\n",
    "    ax.plot(cur_model[:,0],cur_model[:,1],color=\"blue\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"discussion\"><b>Discussion</b></div>\n",
    "\n",
    "1. Which model has high variance, which has high bias? \n",
    "2. What makes a model high variance or high bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In R**  \n",
    "\n",
    "We need to:\n",
    " - Import the loess function\n",
    " - Send data over to R\n",
    " - Call the function and get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_loess = robjects.r['loess.smooth'] #extract R function\n",
    "r_y = robjects.FloatVector(diab['y'])\n",
    "r_age = robjects.FloatVector(diab['age'])\n",
    "\n",
    "ss1_r = r_loess(r_age,r_y, span=0.15, degree=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss1_r #again, a smoothed y value for each x value in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 3</b></div>\n",
    "\n",
    "Predict the output of\n",
    "1. `ss1_r[0]`\n",
    "2. `ss1_r.rx2(\"y\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Varying span**  \n",
    "Next, some extremely clean code to fit and plot models with various parameter settings. (Though the `zip()` method seen earlier is great when e.g. the label and the parameter differ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cur_frac in [0.15,0.25,0.7,1]:\n",
    "    \n",
    "    cur_smooth = r_loess(r_age,r_y, span=cur_frac)\n",
    "\n",
    "    ax = diab.plot.scatter(x='age',y='y',c='Red',title=\"Lowess Fit, Fraction = {}\".format(cur_frac))\n",
    "    ax.set_xlabel(\"Age at Diagnosis\")\n",
    "    ax.set_ylabel(\"Log C-Peptide Concentration\")\n",
    "    ax.plot(cur_smooth[0], cur_smooth[1], color=\"blue\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"discussion\"><b>Discussion</b></div>\n",
    "\n",
    "- Mark wasn't kidding; the Python and R results differ for frac=.15. Thoughts?\n",
    "- Why isn't the bottom plot a straight line? We're using 100% of the data in each window..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing Splines\n",
    "From this point forward, we're working with R functions; these models aren't (well) supported in Python.\n",
    "\n",
    "For clarity: this is the fancy spline model that minimizes $MSE - \\lambda\\cdot\\text{wiggle penalty}$ $=$ $\\sum_{i=1}^N \\left(y_i - f(x_i)\\right)^2 - \\lambda \\int \\left(f''(x)\\right)^2$, across all possible functions $f$. The winner will always be a continuous, cubic polynomial with a knot at each data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"discussion\"><b>Discussion</b></div>\n",
    "\n",
    "- Any idea why the winner is cubic?\n",
    "- How interpretable is this model?\n",
    "- What are the tunable parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_smooth_spline = robjects.r['smooth.spline'] #extract R function\n",
    "\n",
    "# run smoothing function\n",
    "spline1 = r_smooth_spline(r_age, r_y, spar=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 4</b></div>\n",
    "\n",
    "1. We actually set the spar parameter, a scale-free value that translates to a $\\lambda$ through a complex expression. Inspect the 'spline1' result and extract the implied value of $\\lambda$\n",
    "2. Working from the fitting/plotting loop examples above, produce a plot like the one below for spar = [0,.5,.9,2], including axes labels and title."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CV**  \n",
    "R's `smooth_spline` funciton has built-in CV to find a good lambda. See package [docs](https://www.rdocumentation.org/packages/stats/versions/3.5.2/topics/smooth.spline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spline_cv = r_smooth_spline(r_age, r_y, cv=True) \n",
    "\n",
    "lambda_cv = spline_cv.rx2(\"lambda\")[0]\n",
    "\n",
    "ax19 = diab.plot.scatter(x='age',y='y',c='Red',title=\"smoothing spline with $\\lambda=$\"+str(np.round(lambda_cv,4))+\", chosen by cross-validation\")\n",
    "ax19.set_xlabel(\"Age at Diagnosis\")\n",
    "ax19.set_ylabel(\"Log C-Peptide Concentration\")\n",
    "ax19.plot(spline_cv.rx2(\"x\"),spline_cv.rx2(\"y\"),color=\"darkgreen\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"discussion\"><b>Discussion</b></div>\n",
    "\n",
    " - Does the selected model look reasonable?\n",
    " - How would you describe the effect of age at diagnosis on C_peptide concentration?\n",
    " - What are the costs/benefits of the (fancy) spline model, relative to the linear regression we fit above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural & Basis Splines\n",
    "Here, we take a step backward on model complexity, but a step forward in coding complexity. We'll be working with R's formula interface again, so we will need to populate Formulas and DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"discussion\"><b>Discussion</b></div>\n",
    "\n",
    "- In what way are Natural and Basis splines less complex than the splines we were just working with?\n",
    "- What makes a spline 'natural'?\n",
    "- What makes a spline 'basis'?\n",
    "- What are the tuning parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will now work with a new dataset, called GAGurine.\n",
    "#The dataset description (from the R package MASS) is below:\n",
    "#Data were collected on the concentration of a chemical GAG \n",
    "# in the urine of 314 children aged from zero to seventeen years. \n",
    "# The aim of the study was to produce a chart to help a paediatrican\n",
    "# to assess if a child's GAG concentration is ‘normal’.\n",
    "\n",
    "#The variables are:\n",
    "# Age: age of child in years.\n",
    "# GAG: concentration of GAG (the units have been lost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAGurine = pd.read_csv(\"data/GAGurine.csv\")\n",
    "display(GAGurine.head())\n",
    "\n",
    "ax31 = GAGurine.plot.scatter(x='Age',y='GAG',c='black',title=\"GAG in urine of children\")\n",
    "ax31.set_xlabel(\"Age\");\n",
    "ax31.set_ylabel(\"GAG\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard stuff: import function, convert variables to R format, call function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "r_splines = importr('splines')\n",
    "\n",
    "# populate R variables\n",
    "r_gag = robjects.FloatVector(GAGurine['GAG'].values)\n",
    "r_age = robjects.FloatVector(GAGurine['Age'].values)\n",
    "r_quarts = robjects.FloatVector(np.quantile(r_age,[.25,.5,.75])) #woah, numpy functions run on R objects!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens when we call the ns or bs functions from r_splines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_design = r_splines.ns(r_age, knots=r_quarts)\n",
    "bs_design = r_splines.bs(r_age, knots=r_quarts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(ns_design)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ns` and `bs` return design matrices, not model objects! That's because they're meant to work with `lm`'s formula interface. To get a model object we populate a formula including `ns(<var>,<knots>)` and fit to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_lm = robjects.r['lm']\n",
    "r_predict = robjects.r['predict']\n",
    "\n",
    "# populate the formula\n",
    "ns_formula = robjects.Formula(\"Gag ~ ns(Age, knots=r_quarts)\")\n",
    "ns_formula.environment['Gag'] = r_gag\n",
    "ns_formula.environment['Age'] = r_age\n",
    "ns_formula.environment['r_quarts'] = r_quarts\n",
    "         \n",
    "# fit the model\n",
    "ns_model = r_lm(ns_formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict like usual: build a dataframe to predict on and call `predict()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predict_frame = robjects.DataFrame({\"Age\": robjects.FloatVector(np.linspace(0,20,100))})\n",
    "\n",
    "ns_out = r_predict(ns_model, predict_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax32 = GAGurine.plot.scatter(x='Age',y='GAG',c='grey',title=\"GAG in urine of children\")\n",
    "ax32.set_xlabel(\"Age\")\n",
    "ax32.set_ylabel(\"GAG\")\n",
    "ax32.plot(predict_frame.rx2(\"Age\"),ns_out, color='red')\n",
    "ax32.legend([\"Natural spline, knots at quartiles\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 5</b></div>\n",
    "\n",
    "1. Fit a basis spline model with the same knots, and add it to the plot above\n",
    "2. Fit a basis spline with 8 knots placed at [2,4,6...14,16] and add it to the plot above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers:**  \n",
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%R -i overfit_model plot(overfit_model)\n",
    "# we'd get the same diagnostic plot we get from an lm model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAMs\n",
    "We come, at last, to our most advanced model. The coding here isn't any more complex than we've done before, though the behind-the-scenes is awesome.\n",
    "\n",
    "First, let's get our (multivariate!) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kyphosis = pd.read_csv(\"data/kyphosis.csv\")\n",
    "\n",
    "print(\"\"\"\n",
    "# kyphosis - wherther a particular deformation was present post-operation\n",
    "# age - patient's age in months\n",
    "# number - the number of vertebrae involved in the operation\n",
    "# start - the number of the topmost vertebrae operated on\n",
    "\n",
    "\"\"\")\n",
    "display(kyphosis.head())\n",
    "display(kyphosis.describe(include='all'))\n",
    "display(kyphosis.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If there are errors about missing R packages, run the code below:\n",
    "\n",
    "#r_utils = importr('utils')\n",
    "#r_utils.install_packages('codetools')\n",
    "#r_utils.install_packages('gam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit a GAM, we\n",
    " - Import the `gam` library\n",
    " - Populate a formula including `s(<var>)` on variables we want to fit smooths for\n",
    " - Call `gam(formula, family=<string>)` where `family` is a string naming a probability distribution, chosen based on how the response variable is thought to occur. \n",
    " - Rough `family` guidelines:\n",
    "     - Response is binary or \"N occurances out of M tries\", e.g. number of lab rats (out of 10) developing disease: chooose `\"binomial\"`\n",
    "     - Response is a count with no logical upper bound, e.g. number of ice creams sold: choose `\"poisson\"`\n",
    "     - Response is real, with normally-distributed noise, e.g. person's height: choose `\"gaussian\"` (the default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is a Python library in development for using GAMs (https://github.com/dswah/pyGAM)\n",
    "# but it is not yet as comprehensive as the R GAM library, which we will use here instead.\n",
    "\n",
    "# R also has the mgcv library, which implements some more advanced/flexible fitting methods\n",
    "\n",
    "r_gam_lib = importr('gam')\n",
    "r_gam = r_gam_lib.gam\n",
    "\n",
    "r_kyph = robjects.FactorVector(kyphosis[[\"Kyphosis\"]].values)\n",
    "r_Age = robjects.FloatVector(kyphosis[[\"Age\"]].values)\n",
    "r_Number = robjects.FloatVector(kyphosis[[\"Number\"]].values)\n",
    "r_Start = robjects.FloatVector(kyphosis[[\"Start\"]].values)\n",
    "\n",
    "kyph1_fmla = robjects.Formula(\"Kyphosis ~ s(Age) + s(Number) + s(Start)\")\n",
    "kyph1_fmla.environment['Kyphosis']=r_kyph\n",
    "kyph1_fmla.environment['Age']=r_Age\n",
    "kyph1_fmla.environment['Number']=r_Number\n",
    "kyph1_fmla.environment['Start']=r_Start\n",
    "\n",
    "\n",
    "kyph1_gam = r_gam(kyph1_fmla, family=\"binomial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted gam model has a lot of interesting data within it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kyph1_gam.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember plotting? Calling R's `plot()` on a gam model is the easiest way to view the fitted splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R -i kyph1_gam plot(kyph1_gam, residuals=TRUE,se=TRUE, scale=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction works like normal (build a data frame to predict on, if you don't already have one, and call `predict()`). However, predict always reports the sum of the individual variable effects. If `family` is non-default this can be different from the actual prediction for that point.\n",
    "\n",
    "For instance, we're doing a 'logistic regression' so the raw prediction is log odds, but we can get probability by using in `predict(..., type=\"response\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kyph_new = robjects.DataFrame({'Age': robjects.IntVector((84,85,86)), \n",
    "                               'Start': robjects.IntVector((5,3,1)), \n",
    "                               'Number': robjects.IntVector((1,6,10))})\n",
    "\n",
    "print(\"Raw response (so, Log odds):\")\n",
    "display(r_predict(kyph1_gam, kyph_new))\n",
    "print(\"Scaled response (so, probabilty of kyphosis):\")\n",
    "display(r_predict(kyph1_gam, kyph_new, type=\"response\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"discussion\"><b>Discussion</b></div>\n",
    "<div class=\"exercise\"><b>Exercise 6</b></div>\n",
    "\n",
    "1. What lambda did we use? \n",
    "2. What is the model telling us about the effects of age, starting vertebrae, and number of vertebae operated on\n",
    "3. If we fit a logistic regression instead, which variables might want quadratic terms. What is the cost and benefit of a logistic regression model versus a GAM?\n",
    "4. Critique the model: \n",
    "    - What is it assuming? Are the assumptions reasonable\n",
    "    - Are we using the right data?\n",
    "    - Does the model's story about the world make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAMs and smoothing splines support hypothesis tets to compare models. (We can always compare models via out-of-sample prediction quality (i.e. performance on a validation set), but statistical ideas like hypothesis tests yet information criteria allow us to use all data for training *and* still compare the quality of model A to model B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r_anova = robjects.r[\"anova\"]\n",
    "\n",
    "kyph0_fmla = robjects.Formula(\"Kyphosis~1\")\n",
    "kyph0_fmla.environment['Kyphosis']=r_kyph\n",
    "\n",
    "kyph0_gam = r_gam(kyph0_fmla, family=\"binomial\")\n",
    "print(r_anova(kyph0_gam, kyph1_gam, test=\"Chi\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explicitly joining spline functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(x, xi, pow_arg): #pow is a reserved keyword in Python\n",
    "    if (x > xi):\n",
    "        return pow((x-xi),pow_arg)\n",
    "    else:\n",
    "        return 0\n",
    "h = np.vectorize(h,otypes=[np.float]) #default behavior is to return ints, which gives incorrect answer\n",
    "#also, vectorize does not play nicely with default arguments, so better to set directly (e.g., pow_arg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals = np.arange(0,10.1,0.1)\n",
    "ax20 = plt.plot(xvals,h(xvals,4,1),color=\"red\")\n",
    "_ = plt.title(\"Truncated linear basis function with knot at x=4\")\n",
    "_ = plt.xlabel(\"$x$\")\n",
    "_ = plt.ylabel(\"$(x-4)_+$\") #note the use of TeX in the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax21 = plt.plot(xvals,h(xvals,4,3),color=\"red\")\n",
    "_ = plt.title(\"Truncated cubic basis function with knot at x=4\")\n",
    "_ = plt.xlabel(\"$x$\")\n",
    "_ = plt.ylabel(\"$(x-4)_+^3$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax22 = plt.plot(xvals,2+xvals+3*h(xvals,2,1)-4*h(xvals,5,1)+0.5*h(xvals,8,1),color=\"red\")\n",
    "_ = plt.title(\"Piecewise linear spline with knots at x=2, 5, and 8\")\n",
    "_ = plt.xlabel(\"$x$\")\n",
    "_ = plt.ylabel(\"$y$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing splines to the (noisy) model that generated them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0.1,10,9.9/100) \n",
    "from scipy.stats import norm\n",
    "#ppf (percent point function) is the rather unusual name for\n",
    "#the quantile or inverse CDF function in SciPy\n",
    "y = norm.ppf(x/10) + np.random.normal(0,0.4,100)\n",
    "ax23 = plt.scatter(x,y,facecolors='none', edgecolors='black')\n",
    "_ = plt.title(\"3 knots\")\n",
    "_ = plt.xlabel(\"$x$\")\n",
    "_ = plt.ylabel(\"$y$\")\n",
    "_ = plt.plot(x,sm.ols('y~x+h(x,2,1)+h(x,5,1)+h(x,8,1)',data={'x':x,'y':y}).fit().predict(),color=\"darkblue\",linewidth=2)\n",
    "_ = plt.plot(x,norm.ppf(x/10),color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax24 = plt.scatter(x,y,facecolors='none', edgecolors='black')\n",
    "_ = plt.title(\"6 knots\")\n",
    "_ = plt.xlabel(\"$x$\")\n",
    "_ = plt.ylabel(\"$y$\")\n",
    "_ = plt.plot(x,sm.ols('y~x+h(x,1,1)+h(x,2,1)+h(x,3.5,1)+h(x,5,1)+h(x,6.5,1)+h(x,8,1)',data={'x':x,'y':y}).fit().predict(),color=\"darkblue\",linewidth=2)\n",
    "_ = plt.plot(x,norm.ppf(x/10),color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax25 = plt.scatter(x,y,facecolors='none', edgecolors='black')\n",
    "_ = plt.title(\"9 knots\")\n",
    "_ = plt.xlabel(\"$x$\")\n",
    "_ = plt.ylabel(\"$y$\")\n",
    "_ = plt.plot(x,sm.ols('y~x+h(x,1,1)+h(x,2,1)+h(x,3,1)+h(x,4,1)+h(x,5,1)+h(x,6,1)+h(x,7,1)+h(x,8,1)+h(x,9,1)',data={'x':x,'y':y}).fit().predict(),color=\"darkblue\",linewidth=2)\n",
    "_ = plt.plot(x,norm.ppf(x/10),color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regstr = 'y~x+'\n",
    "for i in range(1,26):\n",
    "    regstr += 'h(x,'+str(i/26*10)+',1)+'\n",
    "regstr = regstr[:-1] #drop last +\n",
    "ax26 = plt.scatter(x,y,facecolors='none', edgecolors='black')\n",
    "_ = plt.title(\"25 knots\")\n",
    "_ = plt.xlabel(\"$x$\")\n",
    "_ = plt.ylabel(\"$y$\")\n",
    "_ = plt.plot(x,sm.ols(regstr,data={'x':x,'y':y}).fit().predict(),color=\"darkblue\",linewidth=2)\n",
    "_ = plt.plot(x,norm.ppf(x/10),color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "Try generating random data from different distributions and fitting polynomials of different degrees to it. What do you observe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So, we see that increasing the number of knots results in a more polynomial-like fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next, we look at cubic splines with increasing numbers of knots\n",
    "ax27 = plt.scatter(x,y,facecolors='none', edgecolors='black')\n",
    "_ = plt.title(\"3 knots\")\n",
    "_ = plt.xlabel(\"$x$\")\n",
    "_ = plt.ylabel(\"$y$\")\n",
    "_ = plt.plot(x,sm.ols('y~x+np.power(x,2)+np.power(x,3)+h(x,2,3)+h(x,5,3)+h(x,8,3)',data={'x':x,'y':y}).fit().predict(),color=\"darkblue\",linewidth=2)\n",
    "_ = plt.plot(x,norm.ppf(x/10),color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax28 = plt.scatter(x,y,facecolors='none', edgecolors='black')\n",
    "_ = plt.title(\"6 knots\")\n",
    "_ = plt.xlabel(\"$x$\")\n",
    "_ = plt.ylabel(\"$y$\")\n",
    "_ = plt.plot(x,sm.ols('y~x+np.power(x,2)+np.power(x,3)+h(x,1,3)+h(x,2,3)+h(x,3.5,3)+h(x,5,3)+h(x,6.5,3)+h(x,8,3)',data={'x':x,'y':y}).fit().predict(),color=\"darkblue\",linewidth=2)\n",
    "_ = plt.plot(x,norm.ppf(x/10),color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax29 = plt.scatter(x,y,facecolors='none', edgecolors='black')\n",
    "_ = plt.title(\"9 knots\")\n",
    "_ = plt.xlabel(\"$x$\")\n",
    "_ = plt.ylabel(\"$y$\")\n",
    "_ = plt.plot(x,sm.ols('y~x+np.power(x,2)+np.power(x,3)+h(x,1,3)+h(x,2,3)+h(x,3,3)+h(x,4,3)+h(x,5,3)+h(x,6,3)+h(x,7,3)+h(x,8,3)+h(x,9,3)',data={'x':x,'y':y}).fit().predict(),color=\"darkblue\",linewidth=2)\n",
    "_ = plt.plot(x,norm.ppf(x/10),color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regstr2 = 'y~x+np.power(x,2)+np.power(x,3)+'\n",
    "for i in range(1,26):\n",
    "    regstr2 += 'h(x,'+str(i/26*10)+',3)+'\n",
    "regstr2 = regstr2[:-1] #drop last +\n",
    "ax30 = plt.scatter(x,y,facecolors='none', edgecolors='black')\n",
    "_ = plt.title(\"25 knots\")\n",
    "_ = plt.xlabel(\"$x$\")\n",
    "_ = plt.ylabel(\"$y$\")\n",
    "_ = plt.plot(x,sm.ols(regstr2,data={'x':x,'y':y}).fit().predict(),color=\"darkblue\",linewidth=2)\n",
    "_ = plt.plot(x,norm.ppf(x/10),color=\"red\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
